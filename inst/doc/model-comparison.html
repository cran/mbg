<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Model validation and comparison</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Model validation and comparison</h1>



<p>The <code>mbg</code> package allows for easy customization of geostatistical models: for example, it is simple to test models with varying covariate sets, approaches for relating covariates to the outcome, and combinations of model effects. This leads to the obvious question of which model is best for the situation at hand. In this article, we explore how to compare models using standard predictive validity metrics and k-fold cross-validation.</p>
<div id="predictive-validity-metrics" class="section level1">
<h1>Predictive validity metrics</h1>
<p>In this tutorial, we will generate the following metrics to assess and compare models:</p>
<div id="log-predictive-density" class="section level2">
<h2>Log predictive density</h2>
<p>In a Bayesian context, we would ideally like to evaluate a posterior predictive distribution <span class="math inline">\(p_{posterior}(\theta)\)</span> against some new data <span class="math inline">\(\tilde{y}\)</span> drawn from the true underlying distribution. If we had this newly-observed data, we could calculate the probability of observing each new point given the predictive distribution, then multiply these across <em>N</em> observations to get the overall <em>predictive density (PD)</em>:</p>
<p><span class="math display">\[
PD = p(\tilde{y}|\theta) = \prod_{i=1}^{N} p(\tilde{y}_i | \theta)
\]</span></p>
<p>When comparing two models against the same new data, the model with the higher predictive density can be considered more consistent with that data.</p>
<p>To make the computation more tractable, we can take the log of both sides to calculate <em>log predictive density (LPD)</em>:</p>
<p><span class="math display">\[
LPD = \sum_{i=1}^N \log{ p(\tilde{y}_i | \theta) }
\]</span></p>
<p>Because we are working with posterior samples rather than the full distribution, we will average density across the set of predictive samples <span class="math inline">\(S\)</span> to approximate LPD:</p>
<p><span class="math display">\[
\widehat{LPD} = \sum_{i=1}^{N} \log \left( \frac{1}{S} \sum_{s=1}^{S} p(\tilde{y}_i | \theta_s) \right)
\]</span></p>
<p>In the notation above, we are repeatedly evaluating each data point <span class="math inline">\(i\)</span> (for <span class="math inline">\(i\)</span> = 1 to <em>N</em>) against each predictive posterior draw <em>s</em> (for <em>s</em> = 1 to <em>S</em>).</p>
<p>The LPD is expressed as a negative number—smaller negative numbers (those closer to zero) indicate a higher predictive density and therefore a better predictive fit.</p>
</div>
<div id="watanabe-aikake-information-criterion" class="section level2">
<h2>Watanabe-Aikake information criterion</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Watanabe%E2%80%93Akaike_information_criterion">Watanabe-Aikake information criterion</a> (WAIC, also called the “widely applicable information criterion”) estimates how well a Bayesian model might fit to new data without actually performing cross-validation. It is calculated as the log pointwise predictive density (LPD, for data used to train the model) and penalized by a term that is larger for more flexible models.</p>
<p>Like other information criteria, WAIC is expressed as a positive number, where smaller numbers indicate a better fit.</p>
</div>
<div id="root-mean-squared-error" class="section level2">
<h2>Root mean squared error</h2>
<p>Root mean squared error will be familiar to anyone who has taken an introductory statistics course:</p>
<p><span class="math display">\[
RMSE = \sqrt{ \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i )^{2} }
\]</span></p>
<p>In this context, <span class="math inline">\(y_i\)</span> is the observed <em>rate</em> of the outcome (calculated as the number of positives divided by the sample size) at data point <span class="math inline">\(i\)</span>, while <span class="math inline">\(\hat{y}_i\)</span> is the model’s <em>mean prediction</em> at the pixel that overlaps with data point <span class="math inline">\(i\)</span>. RMSE can be calculated “in-sample” against data that was used to fit the model, or “out-of-sample” against data that was held back from the model.</p>
<p>RMSE is simple to interpret; it can also be used as a point of comparison against frequentist estimates like those generated by the machine learning submodels. However, using RMSE to evalulate geostatistical models has downsides:</p>
<ul>
<li>Differences in data sample size are ignored: an observation of 1 positive/4 sampled is identical to an observation of 250 positive/1,000 sampled when calculating <span class="math inline">\(y_i\)</span>.</li>
<li>The uncertainty of model estimates is not taken into account: two models with the same mean estimates but different uncertainty intervals would end up with the same <span class="math inline">\(\hat{y}_i\)</span> values and therefore identical RMSE.</li>
</ul>
<p>For these reasons, we prefer to use the LPD or WAIC for model evaluation, and to use RMSE either as a backup or a tool for specifically evaluating the model’s mean estimates.</p>
</div>
</div>
<div id="model-cross-validation" class="section level1">
<h1>Model cross-validation</h1>
<p>When calculating predictive validity metrics like LPD and RMSE, we have a tension between (1) wanting to use all available data to fit the model and (2) wanting to hold back some data for model validation. We can deal with this tension using cross-validation.</p>
<p>In <strong>leave one out cross validation</strong>, we evaluate each data point <span class="math inline">\(y_i\)</span> against a model that was trained on the entire dataset <em>except</em> for <span class="math inline">\(y_i\)</span>; we calculate each model’s predictive validity against the one unobserved data point, then summarize those predictive validity metrics (summing LPD and RMSE) across all subset models. In the aggregate, the performance of each subset model against held-out data points should be similar to the full model’s predictive performance against a theoretical unobserved dataset drawn from the same distribution.</p>
<p>Running one model per data point is often too time-intensive to be practical. We can approximate the performance of leave-one-out cross-validation using <strong>k-folds cross-validation</strong>, where the data is randomly split into <em>k</em> (often <em>k</em> = 5 or 10) “folds” or holdouts. <em>k</em> subset models are run: in each, the fold is reserved as a validation set, and the rest of the data is used to train the subset. Predictive validity metrics are repeatedly calculated for the held-out observations and then combined. When <em>k</em> is large, the combined metrics will approach the values observed in leave-one-out cross-validation.</p>
<p>In this tutorial, we will calculate all three of our standard metrics for the full model; we will then calculate “out-of-sample” LPD and RMSE using 10-fold cross validation.</p>
</div>
<div id="setup" class="section level1">
<h1>Setup</h1>
<p>In this tutorial, we will continue to use example data on child stunting from Benin. We will compare the default <code>mbg</code> model, as described in the <a href="mbg.html">introductory vignette</a>, to a stacked ensemble model with department-level fixed effects, as described in the <a href="model-comparison.html">spatial ML models article</a>.</p>
<p>Start this tutorial by loading the example data and preparing the ID raster:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="co"># Load packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a><span class="kw">library</span>(data.table)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a><span class="kw">library</span>(sf)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a><span class="kw">library</span>(terra)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a><span class="kw">library</span>(mbg)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a><span class="co"># Load input data, covariates, and department boundaries</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>outcomes &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>  <span class="kw">system.file</span>(<span class="st">&#39;extdata/child_stunting.csv&#39;</span>, <span class="dt">package =</span> <span class="st">&#39;mbg&#39;</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a>covariates &lt;-<span class="st"> </span><span class="kw">list</span>(</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>  <span class="dt">access =</span> terra<span class="op">::</span><span class="kw">rast</span>(<span class="kw">system.file</span>(<span class="st">&#39;extdata/access.tif&#39;</span>, <span class="dt">package =</span> <span class="st">&#39;mbg&#39;</span>)),</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>  <span class="dt">evi =</span> terra<span class="op">::</span><span class="kw">rast</span>(<span class="kw">system.file</span>(<span class="st">&#39;extdata/evi.tif&#39;</span>, <span class="dt">package =</span> <span class="st">&#39;mbg&#39;</span>)),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true"></a>  <span class="dt">temperature =</span> terra<span class="op">::</span><span class="kw">rast</span>(<span class="kw">system.file</span>(<span class="st">&#39;extdata/temperature.tif&#39;</span>, <span class="dt">package =</span> <span class="st">&#39;mbg&#39;</span>))</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true"></a>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true"></a>covariates<span class="op">$</span>intercept &lt;-<span class="st"> </span>covariates[[<span class="dv">1</span>]] <span class="op">*</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true"></a>departments &lt;-<span class="st"> </span>sf<span class="op">::</span><span class="kw">st_read</span>(</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true"></a>  <span class="kw">system.file</span>(<span class="st">&#39;extdata/Benin_departments.gpkg&#39;</span>, <span class="dt">package =</span> <span class="st">&#39;mbg&#39;</span>),</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true"></a>  <span class="dt">quiet =</span> <span class="ot">TRUE</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true"></a>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true"></a><span class="co"># Create ID raster</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true"></a>id_raster &lt;-<span class="st"> </span>mbg<span class="op">::</span><span class="kw">build_id_raster</span>(</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true"></a>  <span class="dt">polygons =</span> departments,</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true"></a>  <span class="dt">template_raster =</span> covariates[[<span class="dv">1</span>]]</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true"></a>)</span></code></pre></div>
</div>
<div id="in-sample-model-comparison" class="section level1">
<h1>In-sample model comparison</h1>
<p>First, run both the standard and stacking model types using the full dataset. These are the “in-sample” models, as no data was reserved for validation.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="co"># Standard model (in-sample)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>standard_model_is &lt;-<span class="st"> </span>mbg<span class="op">::</span>MbgModelRunner<span class="op">$</span><span class="kw">new</span>(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>  <span class="dt">input_data =</span> outcomes,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>  <span class="dt">id_raster =</span> id_raster,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>  <span class="dt">covariate_rasters =</span> covariates,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>  <span class="dt">verbose =</span> <span class="ot">FALSE</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>standard_model_is<span class="op">$</span><span class="kw">run_mbg_pipeline</span>()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a><span class="co"># Stacked generalization model (in-sample)</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a><span class="co"># Same cross-validation settings</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a>cross_validation_settings &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">method =</span> <span class="st">&#39;repeatedcv&#39;</span>, <span class="dt">number =</span> <span class="dv">5</span>, <span class="dt">repeats =</span> <span class="dv">5</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>submodel_settings &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">enet =</span> <span class="ot">NULL</span>, <span class="dt">gbm =</span> <span class="kw">list</span>(<span class="dt">verbose =</span> <span class="ot">FALSE</span>), <span class="dt">treebag =</span> <span class="ot">NULL</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a>stacking_model_is &lt;-<span class="st"> </span>mbg<span class="op">::</span>MbgModelRunner<span class="op">$</span><span class="kw">new</span>(</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true"></a>  <span class="dt">input_data =</span> outcomes,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true"></a>  <span class="dt">id_raster =</span> id_raster,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true"></a>  <span class="dt">covariate_rasters =</span> covariates,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true"></a>  <span class="dt">use_stacking =</span> <span class="ot">TRUE</span>,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true"></a>  <span class="dt">stacking_cv_settings =</span> cross_validation_settings,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true"></a>  <span class="dt">stacking_model_settings =</span> submodel_settings,</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true"></a>  <span class="dt">stacking_prediction_range =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true"></a>  <span class="dt">stacking_use_admin_bounds =</span> <span class="ot">TRUE</span>,</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true"></a>  <span class="dt">admin_bounds =</span> departments,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true"></a>  <span class="dt">admin_bounds_id =</span> <span class="st">&#39;department_code&#39;</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true"></a>  <span class="dt">verbose =</span> <span class="ot">FALSE</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true"></a>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true"></a>stacking_model_is<span class="op">$</span><span class="kw">run_mbg_pipeline</span>()</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true"></a><span class="co">#&gt; Loading required package: ggplot2</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true"></a><span class="co">#&gt; Loading required package: lattice</span></span></code></pre></div>
<p>Use the <code>MbgModelRunner$get_predictive_validity()</code> method to calculate in-sample LPD, WAIC, and RMSE for each model:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>standard_model_metrics &lt;-<span class="st"> </span>standard_model_is<span class="op">$</span><span class="kw">get_predictive_validity</span>()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>standard_model_metrics<span class="op">$</span>model_type &lt;-<span class="st"> &quot;Standard&quot;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>stacking_model_metrics &lt;-<span class="st"> </span>stacking_model_is<span class="op">$</span><span class="kw">get_predictive_validity</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>stacking_model_metrics<span class="op">$</span>model_type &lt;-<span class="st"> &quot;Stacked ensemble&quot;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>metrics_in_sample &lt;-<span class="st"> </span><span class="kw">rbind</span>(</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>  standard_model_metrics,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>  stacking_model_metrics</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>metrics_in_sample</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a><span class="co">#&gt;      rmse_is    lpd_is  waic_is       model_type</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a><span class="co">#&gt;        &lt;num&gt;     &lt;num&gt;    &lt;num&gt;           &lt;char&gt;</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a><span class="co">#&gt; 1: 0.1285057 -1206.084 2397.115         Standard</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a><span class="co">#&gt; 2: 0.1163582 -1156.990 2304.211 Stacked ensemble</span></span></code></pre></div>
<p>The stacked ensemble model has a slightly lower RMSE and a higher (less negative) LPD, indicating a closer fit to the observed data. However, this may just indicate a more flexible model fit—overfitting could lead to worse model performance when comparing against new, unobserved data.</p>
<p>We can also calculate the in-sample RMSE of each component ML model from the stacked ensemble model:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>outcomes[, data_rate <span class="op">:</span><span class="er">=</span><span class="st"> </span>indicator <span class="op">/</span><span class="st"> </span>samplesize]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>ml_submodels &lt;-<span class="st"> </span>stacking_model_is<span class="op">$</span>model_covariates</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>submodel_rmse &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">data.table</span>(</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>  <span class="dt">rmse_is =</span> <span class="kw">c</span>(</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>    mbg<span class="op">::</span><span class="kw">rmse_raster_to_point</span>(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>      <span class="dt">estimates =</span> ml_submodels<span class="op">$</span>enet,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a>      <span class="dt">validation_data =</span> outcomes,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a>      <span class="dt">outcome_field =</span> <span class="st">&#39;data_rate&#39;</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a>    ),</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a>    mbg<span class="op">::</span><span class="kw">rmse_raster_to_point</span>(</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true"></a>      <span class="dt">estimates =</span> ml_submodels<span class="op">$</span>gbm,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true"></a>      <span class="dt">validation_data =</span> outcomes,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true"></a>      <span class="dt">outcome_field =</span> <span class="st">&#39;data_rate&#39;</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true"></a>    ),</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true"></a>    mbg<span class="op">::</span><span class="kw">rmse_raster_to_point</span>(</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true"></a>      <span class="dt">estimates =</span> ml_submodels<span class="op">$</span>treebag,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true"></a>      <span class="dt">validation_data =</span> outcomes,</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true"></a>      <span class="dt">outcome_field =</span> <span class="st">&#39;data_rate&#39;</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true"></a>    )</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true"></a>  ),</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true"></a>  <span class="dt">model_type =</span> <span class="kw">c</span>(<span class="st">&#39;Elastic net&#39;</span>, <span class="st">&#39;Gradient boosted machines&#39;</span>, <span class="st">&#39;Bagged regression trees&#39;</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true"></a>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true"></a>submodel_rmse</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true"></a><span class="co">#&gt;      rmse_is                model_type</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true"></a><span class="co">#&gt;        &lt;num&gt;                    &lt;char&gt;</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true"></a><span class="co">#&gt; 1: 0.1357682               Elastic net</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true"></a><span class="co">#&gt; 2: 0.1268371 Gradient boosted machines</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true"></a><span class="co">#&gt; 3: 0.1157924   Bagged regression trees</span></span></code></pre></div>
</div>
<div id="out-of-sample-model-comparison" class="section level1">
<h1>Out-of-sample model comparison</h1>
<p>To better approximate model performance with unobserved data, we will perform 10-fold validation using the input dataset. This requires running both the standard and stacking models 10 times on different subsets of the observed point data. For each of the 10 sub-models, we generate predictive validity metrics based on the held-out portion of the data.</p>
<p>Note that WAIC is an in-sample predictive validity metric: because <code>in_sample = FALSE</code>, WAIC is not generated during these runs.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co"># Assign a new `holdout_id` field in the data, which are shuffled integers from 1 to 10</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a>n_holdouts &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>outcomes<span class="op">$</span>holdout_id &lt;-<span class="st"> </span><span class="kw">seq_len</span>(n_holdouts) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">rep</span>(<span class="dt">length.out =</span> <span class="kw">nrow</span>(outcomes)) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a><span class="st">  </span><span class="kw">sample</span>()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a><span class="co"># For each of the 10 holdouts, get both models&#39; *out-of-sample* predictive validity</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>metrics_by_holdout &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="kw">seq_len</span>(n_holdouts), <span class="cf">function</span>(holdout){</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>  <span class="co"># Split into (observed) training data and (unobserved) testing data</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a>  train &lt;-<span class="st"> </span>outcomes[holdout_id <span class="op">!=</span><span class="st"> </span>holdout,]</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a>  test &lt;-<span class="st"> </span>outcomes[holdout_id <span class="op">==</span><span class="st"> </span>holdout,]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>  <span class="co"># Run both models</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true"></a>  standard_model_oos &lt;-<span class="st"> </span>mbg<span class="op">::</span>MbgModelRunner<span class="op">$</span><span class="kw">new</span>(</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true"></a>    <span class="dt">input_data =</span> train,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true"></a>    <span class="dt">id_raster =</span> id_raster,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true"></a>    <span class="dt">covariate_rasters =</span> covariates,</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true"></a>    <span class="dt">verbose =</span> <span class="ot">FALSE</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true"></a>  )</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true"></a>  standard_model_oos<span class="op">$</span><span class="kw">run_mbg_pipeline</span>()</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true"></a>  stacking_model_oos &lt;-<span class="st"> </span>mbg<span class="op">::</span>MbgModelRunner<span class="op">$</span><span class="kw">new</span>(</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true"></a>    <span class="dt">input_data =</span> train,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true"></a>    <span class="dt">id_raster =</span> id_raster,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true"></a>    <span class="dt">covariate_rasters =</span> covariates,</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true"></a>    <span class="dt">use_stacking =</span> <span class="ot">TRUE</span>,</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true"></a>    <span class="dt">stacking_cv_settings =</span> cross_validation_settings,</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true"></a>    <span class="dt">stacking_model_settings =</span> submodel_settings,</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true"></a>    <span class="dt">stacking_prediction_range =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true"></a>    <span class="dt">stacking_use_admin_bounds =</span> <span class="ot">TRUE</span>,</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true"></a>    <span class="dt">admin_bounds =</span> departments,</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true"></a>    <span class="dt">admin_bounds_id =</span> <span class="st">&#39;department_code&#39;</span>,</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true"></a>    <span class="dt">verbose =</span> <span class="ot">FALSE</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true"></a>  )</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true"></a>  stacking_model_oos<span class="op">$</span><span class="kw">run_mbg_pipeline</span>()</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true"></a>  <span class="co"># Compare to the test data</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true"></a>  standard_metrics &lt;-<span class="st"> </span>standard_model_oos<span class="op">$</span><span class="kw">get_predictive_validity</span>(</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true"></a>    <span class="dt">in_sample =</span> <span class="ot">FALSE</span>,</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true"></a>    <span class="dt">validation_data =</span> test</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true"></a>  )[, model_type <span class="op">:</span><span class="er">=</span><span class="st"> &#39;Standard&#39;</span>]</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true"></a>  stacking_metrics &lt;-<span class="st"> </span>stacking_model_oos<span class="op">$</span><span class="kw">get_predictive_validity</span>(</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true"></a>    <span class="dt">in_sample =</span> <span class="ot">FALSE</span>,</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true"></a>    <span class="dt">validation_data =</span> test</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true"></a>  )[, model_type <span class="op">:</span><span class="er">=</span><span class="st"> &#39;Stacked ensemble&#39;</span>]</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true"></a>  this_holdout_metrics &lt;-<span class="st"> </span><span class="kw">rbind</span>(standard_metrics, stacking_metrics)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true"></a>  this_holdout_metrics<span class="op">$</span>holdout_id &lt;-<span class="st"> </span>holdout</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true"></a>  <span class="co"># Return the combined metrics for this holdout</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true"></a>  <span class="kw">return</span>(this_holdout_metrics)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true"></a>}) <span class="op">|</span><span class="er">&gt;</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true"></a><span class="st">  </span>data.table<span class="op">::</span><span class="kw">rbindlist</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">rmse_oos</th>
<th align="right">lpd_oos</th>
<th align="left">model_type</th>
<th align="right">holdout_id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.1179354</td>
<td align="right">-118.7490</td>
<td align="left">Standard</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">0.1252479</td>
<td align="right">-120.7753</td>
<td align="left">Stacked ensemble</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">0.1291436</td>
<td align="right">-120.6255</td>
<td align="left">Standard</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">0.1192507</td>
<td align="right">-117.7843</td>
<td align="left">Stacked ensemble</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">0.1496129</td>
<td align="right">-126.8926</td>
<td align="left">Standard</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">0.1504705</td>
<td align="right">-128.2862</td>
<td align="left">Stacked ensemble</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="right">0.1414287</td>
<td align="right">-125.6910</td>
<td align="left">Standard</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="right">0.1419527</td>
<td align="right">-128.7975</td>
<td align="left">Stacked ensemble</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">0.1363021</td>
<td align="right">-131.5173</td>
<td align="left">Standard</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="right">0.1386044</td>
<td align="right">-136.6189</td>
<td align="left">Stacked ensemble</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">0.1391739</td>
<td align="right">-123.5967</td>
<td align="left">Standard</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">0.1345811</td>
<td align="right">-121.4608</td>
<td align="left">Stacked ensemble</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="right">0.1388889</td>
<td align="right">-118.9464</td>
<td align="left">Standard</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="right">0.1414557</td>
<td align="right">-121.3938</td>
<td align="left">Stacked ensemble</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="right">0.1252319</td>
<td align="right">-122.7438</td>
<td align="left">Standard</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">0.1268031</td>
<td align="right">-124.5918</td>
<td align="left">Stacked ensemble</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">0.1466681</td>
<td align="right">-127.1125</td>
<td align="left">Standard</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="right">0.1383814</td>
<td align="right">-124.0828</td>
<td align="left">Stacked ensemble</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="right">0.1374990</td>
<td align="right">-123.0405</td>
<td align="left">Standard</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">0.1483755</td>
<td align="right">-129.3895</td>
<td align="left">Stacked ensemble</td>
<td align="right">10</td>
</tr>
</tbody>
</table>
<p>The models trade off for better performance across the ten holdout folds. To get an overall comparison of out-of-sample predictive validity, we combine these metrics across holdouts:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>out_of_sample_overall &lt;-<span class="st"> </span>metrics_by_holdout[</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>  , .(<span class="dt">rmse_oos =</span> <span class="kw">mean</span>(rmse_oos), <span class="dt">lpd_oos =</span> <span class="kw">sum</span>(lpd_oos)),</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>  by =<span class="st"> </span>model_type</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>]</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">model_type</th>
<th align="right">rmse_oos</th>
<th align="right">lpd_oos</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Standard</td>
<td align="right">0.1361885</td>
<td align="right">-1238.915</td>
</tr>
<tr class="even">
<td align="left">Stacked ensemble</td>
<td align="right">0.1365123</td>
<td align="right">-1253.181</td>
</tr>
</tbody>
</table>
<p>In this case, the standard model has better out-of-sample LPD and RMSE, suggesting that it is the superior model for predicting new child stunting observations in Benin.</p>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>We can generalize this tutorial into a general strategy for comparing predictive models in a particular country/outcome/dataset context:</p>
<ol style="list-style-type: decimal">
<li>Select the universe of model types to test</li>
<li>Before running any models, select the criteria for model selection. We recommend out-of-sample LPD as the primary criterion for model selection, with out-of-sample RMSE as a tie-breaker for models with near-identical LPD.</li>
<li>Split the data into <em>k</em> holdouts. Run a model for each holdout, evaluating the subset model against the held-out data. <em>Model comparisons should always be run against the same outcomes dataset and holdouts.</em></li>
<li>Based on the criteria selected in (2), choose the model with the top performance</li>
<li>Run a full model with this same specification using all observations (no holdouts). These are the best results from this comparison round.</li>
</ol>
<div id="further-reading" class="section level2">
<h2>Further reading</h2>
<p>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2017). Model assessment and selection. <em>The elements of statistical learning: data mining, inference, and prediction (2E)</em>, 219-259. <a href="https://hastie.su.domains/ElemStatLearn/" class="uri">https://hastie.su.domains/ElemStatLearn/</a></p>
<p>Vehtari, A., Gelman, A., &amp; Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and computing</em>, 27, 1413-1432. <a href="https://link.springer.com/article/10.1007/s11222-016-9696-4" class="uri">https://link.springer.com/article/10.1007/s11222-016-9696-4</a></p>
<p>Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. <em>Journal of machine learning research</em>, 11(12). <a href="https://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf" class="uri">https://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf</a></p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
